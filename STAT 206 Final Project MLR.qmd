---
title: "STAT 206 Final Project MLR"
author: "Axel Galicia Lona, Linlin Liu, amd Nancy Lopez"
date: "2024-12-13"
echo: true
format:
  html:
    toc: true
    toc-location: left
    embed-resources: true
    code-line-numbers: true
  pdf:
    code-line-numbers: true
---

\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\listoftables
\newpage

# Introduction

## Background and Motivation

Movies are a visual art form that simulates and communicates thoughts, actions,
ideas, and realities by combining camera recordings with sound. With rapid
population expansion and technical improvement, the movie industry grows
increasingly sophisticated. The industry's maturity has also boosted the rate
at which movies are made and produced, and every year, a new batch of films is  released in theaters. Therefore, studios, producers, and investors need
reliable predictions to make informed decisions about budgeting, marketing,
and resource allocation.

As viewers, we are also interested in the factors that contribute to a film's
revenue, because these generally define its success. Furthermore, the highly competitive nature of the film industry, as well as the huge economic impact of
movie income, motivated us to pursue this project. With abundant data available
on various aspects of movies, including budget, cast, genre, release dates, and
social media buzz, applying statistical models becomes a valuable tool for
analysis. Thus, we chose to build a multilinear regression model for our
project.

Differential privacy is crucial for datasets containing sensitive aspects of
movies, such as budget, revenue, cast, and others, as it ensures that
individual data points cannot be traced back to their sources. For instance, protecting details like a movie's budget prevents competitors from exploiting financial strategies, while preserving anonymity in user-related data
safeguards privacy rights. By adding controlled random noise to the data,
differential privacy balances utility with confidentiality, enabling meaningful analysis without exposing proprietary or personal information.

## Objectives

This project aims to deepen the understanding of how different factors may
impact a movie’s revenue and to what degree they will influence the box office.
In other words, we aim to determine whether the data provides sufficient
evidence to indicate that these variables contribute information for the
prediction of a movie’s revenue. If so, we seek to identify which variables
contribute the most to accurate predictions. Moreover, we would like to explore
the possibility of protecting sensitive information in the data set by adding a controlled amount of random noise using differential privacy.

These will be achieved by analyzing the data set *movies.csv*, which samples
various components of a movie, including genre, release date, budget,
production company, and cast, from 722,463 movies.

## Hypotheses

Based on the information provided by the data set, we propose the following hypotheses:

1. Different attributes of a feature movie significantly impacts its revenue.

2. A movie’s budget and genre contribute more significantly than others.

# Data Cleaning

Having an original data set of 722,463 observations and 20 variables would make
it rather difficult for us to build a model and increase the model complexity,
so we first decided to eliminate 12 variables as the first step of our data
cleaning process.

Next, we further cleaned the data set by completing the following:

* Omitted all NA's and 0's

* Chose movies with revenue and budget greater than or equal to $10,000

* Chose movies with run time greater than or equal to 40 minutes

* Chose movies with vote count greater than or equal to 95

* Chose movies with vote average greater than 0

The above left us with a data set of 6,804 observations and 8 variables.
However, due to the concern that having too many categories in our chosen
categorical variables, we decided to chose the top two categories for each. We
also divided all variables with unites in dollars by 1,000 for to facilitate
analysis. At the end, we obtained a total of 2,624 observations and 8 variables
as the final data set.

**NOTE:** For the code, please refer to the "Data Cleaning" section in the
Appendix.

# Data Description

For the model building process, we will now be working with the following
variables:

- *genres*: genre of the movie

- *original language*: the language in which the movie was first released

- *popularity*: the amount of times a movie’s page has been visited according
to TMDB metric

- *budget*: the total projected costs of making a movie

- *runtime*: duration of the movie

- *vote average*: average of votes given by TMDB users

- *vote count*: total number of TMDB votes a movie received

- *revenue*: the amount of money a movie raised by ticket sales, output target

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline 
Variable & Unit & Type & Min & Max & SD\\
\hline 
genres & Drama or Comedy & cat predictor & - & - & -\\
\hline 
original language & en or fr & cat predictor & - & - & -\\
\hline
popularity & - & num cont predictor & 0.82 & 3,994.34 & 86.44\\
\hline 
budget & thousand dollars & num cont predictor & 12.00 & 20,000.00 & 23,242.17\\
\hline
runtime & minutes & num cont predictor & 62 & 254 & 20.05\\
\hline
vote average & - & num disc predictor & 3.30 & 8.71 & 0.76\\
\hline
vote count & - & num disc predictor & 95 & 31,145 & 2,543.94\\
\hline
revenue & thousand dollars & num cont response & 10.16 & 2,187,464.00 & 101,669.80\\
\hline
\end{tabular}
\end{center}
\caption{Data Summary Statistics}
\end{table}

**NOTE:** The above variables are the ones found in the original data set. If necessary, we will transform or eliminate variables during model building to
facilitate the process. For more details, please refer to the "Model Building
and Diagnostics" section in the Appendix.

\newpage

# Appendix

## Data Cleaning

```{r, message=FALSE,warning=FALSE, include=FALSE}
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(car)
library(mltools)
library(data.table)
library(fastDummies)
library(lmtest)
library(tidyr)
library(grid)
library(scales)
library(forcats)

original <- read.csv(file.choose(), header = T)
```

```{r, message=FALSE, warning=FALSE}
# subset data
sub1 <- subset(original, select = c("genres", "original_language",
                                    "popularity","budget","revenue",
                                    "runtime","vote_average", "vote_count"))


# replace all empty cells and 0's with NA
sub1[sub1 == ""] = NA
sub1[sub1 == 0] = NA

# clean the data with selected restrictions
sub2 <- sub1 %>%
  na.omit() %>%
  filter(revenue >= 10000) %>%
  filter(budget >= 10000) %>%
  filter(runtime >= 40) %>%
  filter(vote_count >= 95) %>%
  filter(vote_average > 0) 

# split genres and find the top 2 genres
genre <- strsplit(sub2$genres, "-")
sub2$genres <- as.character(lapply(genre, function(x) x[1]))
genre_freq <- table(sub2$genres)
genre_rank <- sort(genre_freq,decreasing = T)
genre_rank[1:2]

# find the top 2 original languages
lang_freq <- table(sub2$original_language)
lang_rank <- sort(lang_freq, decreasing = T)
lang_rank[1:2]

# subset again using only the top 2 genres and the top 2 original languages
# this is the final data set to be used for model building
sub3 <- sub2 %>%
  filter(genres == "Drama" | genres == "Comedy") %>%
  filter(original_language == "en" | original_language == "fr")

# divide revenue and budget by 1000 for easier calculations and visualization
sub3$budget <- as.numeric(as.character(sub3$budget)) / 1000
sub3$revenue <- as.numeric(as.character(sub3$revenue)) / 1000
```

## EDA

```{r fig.cap="Histogram of Response Variable", message=FALSE, warning=FALSE}

# we need to check normality of the y values before any analysis

ggplot(sub3, aes(x = revenue)) +
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand dollars)", y = "count")
```
```{r fig.cap="Histograms and Barplots of Predictor Variables", message=FALSE, warning=FALSE}

# analzyze the predictor variables

g1 <-ggplot(sub3, aes(x = genres)) + 
  geom_bar(fill = "darkblue", color = "white")
g2 <-ggplot(sub3, aes(x = original_language)) + 
  geom_bar(fill = "darkblue", color = "white")
g3 <-ggplot(sub3, aes(x = popularity)) +
  geom_histogram(fill = "darkblue", color = "white", binwidth = 50)
g4 <-ggplot(sub3, aes(x = budget)) + 
  geom_histogram(fill = "darkblue", color = "white")
g5 <-ggplot(sub3, aes(x = runtime)) + 
  geom_histogram(fill = "darkblue", color = "white")
g6 <-ggplot(sub3, aes(x = vote_average)) + 
  geom_histogram(fill = "darkblue", color = "white")
g7<-ggplot(sub3, aes(x = vote_count)) + 
  geom_histogram(fill = "darkblue", color = "white")

grid.arrange(g1, g2, g3, g4, g5, g6, g7, ncol = 2)

```
```{r fig.cap="Predictor vs. Response", message=FALSE, warning=FALSE}

# create scatter plots between each quantitative predictor var and the response var to see their relationships

s.popularity <- ggplot(sub3, aes(x = popularity, y = revenue)) +
  geom_point(color = "darkblue") 
s.budget <- ggplot(sub3, aes(x = budget, y = revenue)) +
  geom_point(color = "darkblue") 
s.runtime <- ggplot(sub3, aes(x = runtime, y = revenue)) +
  geom_point(color = "darkblue") 
s.vote_average <- ggplot(sub3, aes(x = vote_average, y = revenue)) +
  geom_point(color = "darkblue") 
s.vote_count <- ggplot(sub3, aes(x = vote_count, y = revenue)) +
  geom_point(color = "darkblue")

## create boxplots between each categorical predictor and the response

box.genres <- ggplot(sub3, aes(x = genres, y = revenue)) +
           geom_boxplot(color = "darkblue", outlier.color = "red",
                        outlier.shape = 4, outlier.size = 2) 
box.original_language <- ggplot(sub3, aes(x = original_language, y = revenue)) +
              geom_boxplot(color = "darkblue", outlier.color = "red",
                           outlier.shape = 4, outlier.size = 2) 

# divide the frame in grid using grid.arrange() and put above plots in it

grid.arrange(s.popularity, s.budget, s.runtime, s.vote_average, s.vote_count,
             box.genres, box.original_language, ncol = 4, nrow = 2)

```
```{r fig.cap="Initial Pairwise Comparison", message=FALSE, warning=FALSE}

# correlation between variables 

ggpairs(sub3) + theme(axis.text.x = element_text(size= 2, angle = 90),
                      axis.text.y = element_text(size = 2),
                      strip.text.y = element_text(angle = 0))

```


### Forward Stepwise Regression

```{r, message=FALSE, warning=FALSE}
# perform stepwise regression using the original data set

# specify the null model with no predictor
original.null <- lm(revenue ~ 1, data = sub3)
# specify the full model using all of the potential predictors
original.full <- lm(revenue ~ ., data = sub3)
# use the stepwise algorithm to build a parsimonious model
original.step <- step(original.null,
                      scope = list(lower = original.null,
                                   upper = original.full),
                      direction = "both", test = "F")

summary(original.step)
```

According to the final output of the stepwise regression model analysis, the
significant predictors are *vote_count*, *budget*, *popularity*, and *genres*.
Predictors *vote_average* and *runtime* are not statistically significant and
have been excluded from the stepwise model.


## Residual Diagnostics

```{r fig.cap="Residual Diagnostics: Linearity", message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check linearity
ggplot(data = original.step, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Predicted Values", y = "Residuals")
# predictor: vote count
l.vc <- ggplot(data = original.step, aes(x = vote_count, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "vote count", y = "Residuals")
# predictor: budget
l.budget <- ggplot(data = original.step, aes(x = budget, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "budget (in thousand $)", y = "Residuals")
# predictor: popularity
l.popularity <- ggplot(data = original.step, aes(x = popularity, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "popularity", y = "Residuals")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(l.vc, l.budget, l.popularity, ncol = 3, nrow = 1)
```

Only *popularity* passed the linearity check as it showed no distinct pattern.

```{r fig.cap="Residual Diagnostics: Constant Variance", message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check constant variance
bptest(original.step)
```


Because the $p$-value < 2.2$e^{-16}$ is much less than the significance level
$\alpha$ = 0.05, we can reject the null hypothesis. Therefore, there is
sufficient evidence to conclude the residuals do not have constant variance. 

Because the $p$-value < 2.2$e^{-16}$ is much less than the significance level
$\alpha$ = 0.05, we can reject the null hypothesis. Therefore, there is
sufficient evidence to conclude the residuals do not have constant variance. 

```{r fig.cap="Residual Diagnostics: Normality", message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check normality 
ggplot(data = original.step, aes(x = .resid)) + 
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand $)", y = "count")

ggplot(data = original.step, aes(x = .resid)) + 
  geom_boxplot(color = "darkblue", outlier.color = "red",
               outlier.shape = 4, outlier.size = 2) +
           labs(y = "revenue (in thousand $)")

qqnorm(resid(original.step))
qqline(resid(original.step))

shapiro.test(resid(original.step))
```

The residuals do not appear to be normally distributed due to the following
reasons: 

1. The histogram is slightly right-skewed instead of bell-shaped.
2. The mean is not centered at 0 in the boxplot.
3. The right tail of the Q-Q plot deviates significantly from the fitted Q-Q
line.
4. The Shapiro-Wilk test $p$-value < 2.2$e^{-16}$ is much less than the
significance level $\alpha$ = 0.05, suggesting that I can reject the null
hypothesis that the residuals are normally distributed.

```{r, message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check independence
durbinWatsonTest(original.step)
```

Because the $p$-value = 0.608 is greater than the significance level $\alpha$ =
0.05, I cannot reject the null hypothesis. Therefore, there is insufficient
evidence to conclude that the residuals are not independent.

## Model Building and Diagnostics

```{r, message=FALSE, warning=FALSE}
rev <- sub3$revenue
vc <- sub3$vote_count
budget <- sub3$budget
pop <- sub3$popularity
va <- sub3$vote_average
rt <- sub3$runtime

# create dummy variables for each cat var
genre <- ifelse(sub3$genres == "Drama", 1, 0)
o_lang <- ifelse(sub3$original_language == "en", 1, 0)
```

```{r fig.cap="Initial Plots of Predictor vs. Response Variables", message=FALSE, warning=FALSE}
# check the relationship between each predictor var and rev
a <- ggplot(sub3, aes(x = budget, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "revenue (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "revenue (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "revenue (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "revenue (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "revenue (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "revenue (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "revenue (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

### Model Building

```{r fig.cap="Interaction Between popularity and genres", message=FALSE, warning=FALSE}
# check interaction between popularity and genre
plot(pop, rev, type = "n")
points(pop[genre == 0], rev[genre == 0], col="darkblue")
points(pop[genre == 1], rev[genre == 1], col="darkred")
```

The two variables are overlapping, implying an interaction between the two. 

```{r fig.cap="Residual Diagnostics: y1", message=FALSE, warning=FALSE}
lm1 <- lm(rev ~ 0 + pop * genre)
y1 <- lm1$residuals

ggplot(sub3, aes(x = y1))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand $)", y = "count")
qqnorm(y1)
qqline(y1)
shapiro.test(y1)
```

```{r fig.cap="Plots of Predictors vs. y1", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y1
a <- ggplot(sub3, aes(x = budget, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "revenue (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "revenue (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "revenue (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "revenue (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "revenue (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "revenue (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "revenue (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

Model 1 was fitted with an interaction between *popularity* and *generes*, with
an intercept set to 0. 

As shown by the results, Model 1 does not pass the Shapiro-Wilk normality test
and appears right-skewed.

According to the scatter plots for each individual predictor variable against
the Model 1 residuals, most predictors exhibited patterns except for *budget*,
*popularity*, and *vote_count*. These three variables will be further observed
before we decide whether to exclude them in the model.

```{r fig.cap="Residual Diagnostics: y2", message=FALSE, warning=FALSE}
lm2 <- lm(y1 ~ 0 + budget)
y2 <- lm2$residuals

ggplot(sub3, aes(x = y2))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand $)", y = "count")
qqnorm(y2)
qqline(y2)
shapiro.test(y2)
```

```{r fig.cap="Plots of Predictors vs. y2", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y1
a <- ggplot(sub3, aes(x = budget, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "revenue (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "revenue (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "revenue (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "revenue (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "revenue (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "revenue (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "revenue (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

Model 2 was fitted with *budget*, with an intercept set to 0. 

Like Model 1, Model 2 does not pass the Shapiro-Wilk normality test and appears 
right-skewed.

The scatter plots still show that *budget*, *popularity*, and *vote_count* to
have no effect on the response variable Moreover, *genres* seems to have become 
constant as well. Since *budget* and *genres* are the two variables that we 
wanted to focus on as stated in our hypothesis, we have decided to perform a 
logarithmic transformation on *revenue* to see if this will make a difference. 

```{r fig.cap="Plots of Predictor vs. lnrev", message=FALSE, warning=FALSE}
# perform log transformation on revenue and edit the original data set to
# exclude revenue and include lnrev
lnrev <- log(sub3$revenue)
sub3$lnrev <- lnrev
sub3 <- sub3[, -5]

# convert cat vars genres and original language to be binary data
sub3$genres <- genre
sub3$original_language <- o_lang

# check the relationship between each predictor variable and lnrev
a <- ggplot(sub3, aes(x = budget, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "lnrev (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "lnrev (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "lnrev (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "lnrev (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "lnrev (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "lnrev (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "lnrev (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

```{r fig.cap="Interaction Between popularity and genres", message=FALSE, warning=FALSE}
# check interaction between pop and genre
plot(pop, lnrev, type = "n")
points(pop[genre == 0], lnrev[genre == 0], col="darkblue")
points(pop[genre == 1], lnrev[genre == 1], col="darkred")
```

Similar to the results from before, the two variables overlap, suggesting a
strong interaction between them.

```{r fig.cap="Residual Diagnostics: y1", message=FALSE, warning=FALSE}
lm1 <- lm(lnrev ~ 0 + pop * genre)
y1 <- lm1$residuals

ggplot(sub3, aes(x = y1))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")
qqnorm(y1)
qqline(y1)
shapiro.test(y1)
```

```{r fig.cap="Plots of Predictors vs. y1", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y1
a <- ggplot(sub3, aes(x = budget, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand dollars)", y = "lnrev (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "lnrev (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "lnrev (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "lnrev (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "lnrev (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "lnrev (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "lnrev (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

The new Model 1 was fitted with an interaction between *popularity* and
*genres*, with an intercept set to 0. 

It does not pass the Shapiro-Wilk normality test and now appears slightly
left-skewed.

All variables now appear to impact *lnrev* except *vote_average*. This means
that our transformation has made a difference. We will continue to monitor
*vote_average* before deciding whether or not to exclude it from the model.

