---
title: "STAT 206 Final Project MLR and DP Code"
author: "Axel Galicia Lona, Linlin Liu, amd Nancy Lopez"
date: "2024-12-13"
echo: true
format:
  html:
    toc: true
    toc-location: left
    embed-resources: true
    code-line-numbers: true
  pdf:
    code-line-numbers: true
---

# Multiple Linear Regression

## Data Cleaning

Having an original data set of 722,463 observations and 20 variables would make
it rather difficult for us to build a model and increase the model complexity,
so we first decided to eliminate 12 variables as the first step of our data
cleaning process.

Next, we further cleaned the data set by completing the following:

* Omitted all NA's and 0's

* Chose movies with revenue and budget greater than or equal to $10,000

* Chose movies with run time greater than or equal to 40 minutes

* Chose movies with vote count greater than or equal to 95

* Chose movies with vote average greater than 0

The above left us with a data set of 6,804 observations and 8 variables.
However, due to the concern that having too many categories in our chosen
categorical variables, we decided to chose the top two categories for each. We
also divided all variables with unites in dollars by 1,000 for to facilitate
analysis. At the end, we obtained a total of 2,624 observations and 8 variables
as the final data set.

```{r, message=FALSE,warning=FALSE, include=FALSE}
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(car)
library(mltools)
library(data.table)
library(fastDummies)
library(lmtest)
library(tidyr)
library(grid)
library(scales)
library(forcats)

original <- read.csv(file.choose(), header = T)
```

```{r, message=FALSE, warning=FALSE}
# subset data
sub1 <- subset(original, select = c("genres", "original_language",
                                    "popularity","budget","revenue",
                                    "runtime","vote_average", "vote_count"))

# replace all empty cells and 0's with NA
sub1[sub1 == "" | sub1 == 0] <- NA

# clean the data with selected restrictions
sub2 <- sub1 %>%
  na.omit() %>%
  filter(revenue >= 10000) %>%
  filter(budget >= 10000) %>%
  filter(runtime >= 40) %>%
  filter(vote_count >= 95) %>%
  filter(vote_average > 0) 

# split genres and find the top 2 genres
sub2$genres <- sapply(strsplit(sub2$genres, "-"), `[`, 1)
genre_freq <- table(sub2$genres)
genre_rank <- sort(genre_freq, decreasing = TRUE)
head(genre_rank, 2)

# find the top 2 original languages
lang_freq <- table(sub2$original_language)
lang_rank <- sort(lang_freq, decreasing = T)
lang_rank[1:2]

# subset again using only the top 2 genres and the top 2 original languages
# this is the final data set to be used for model building
sub3 <- sub2 %>%
  filter(genres == "Drama" | genres == "Comedy") %>%
  filter(original_language == "en" | original_language == "fr")

# divide revenue and budget by 1000 for easier calculations and visualization
sub3$budget <- as.numeric(as.character(sub3$budget)) / 1000
sub3$revenue <- as.numeric(as.character(sub3$revenue)) / 1000

```

## Data Description

For the model building process, we will now be working with the following
variables:

- *genres*: genre of the movie

- *original language*: the language in which the movie was first released

- *popularity*: the amount of times a movieâ€™s page has been visited according
to TMDB metric

- *budget*: the total projected costs of making a movie

- *runtime*: duration of the movie

- *vote average*: average of votes given by TMDB users

- *vote count*: total number of TMDB votes a movie received

- *revenue*: the amount of money a movie raised by ticket sales, output target

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline 
Variable & Unit & Type & Min & Max & SD\\
\hline 
genres & Drama or Comedy & cat predictor & - & - & -\\
\hline 
original language & en or fr & cat predictor & - & - & -\\
\hline
popularity & - & num cont predictor & 0.82 & 3,994.34 & 86.44\\
\hline 
budget & thousand dollars & num cont predictor & 12.00 & 20,000.00 & 23,242.17\\
\hline
runtime & minutes & num cont predictor & 62 & 254 & 20.05\\
\hline
vote average & - & num disc predictor & 3.30 & 8.71 & 0.76\\
\hline
vote count & - & num disc predictor & 95 & 31,145 & 2,543.94\\
\hline
revenue & thousand dollars & num cont response & 10.16 & 2,187,464.00 & 101,669.80\\
\hline
\end{tabular}
\end{center}
\caption{Data Summary Statistics}
\end{table}

**NOTE:** The above variables are the ones found in the original data set. If necessary, we will transform or eliminate variables during model building to
facilitate the process.

## EDA

```{r fig.cap="Histogram of the Response Variable", message=FALSE, warning=FALSE}
# check normality of the y values before any analysis
ggplot(sub3, aes(x = revenue)) +
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand $)", y = "count")
```

```{r fig.cap="Histograms and Barplots of Predictor Variables", message=FALSE, warning=FALSE}
# analzyze the predictor variables
g1 <-ggplot(sub3, aes(x = genres)) + 
  geom_bar(fill = "darkblue", color = "white")
g2 <-ggplot(sub3, aes(x = original_language)) + 
  geom_bar(fill = "darkblue", color = "white")
g3 <-ggplot(sub3, aes(x = popularity)) +
  geom_histogram(fill = "darkblue", color = "white", binwidth = 50)
g4 <-ggplot(sub3, aes(x = budget)) + 
  geom_histogram(fill = "darkblue", color = "white")
g5 <-ggplot(sub3, aes(x = runtime)) + 
  geom_histogram(fill = "darkblue", color = "white")
g6 <-ggplot(sub3, aes(x = vote_average)) + 
  geom_histogram(fill = "darkblue", color = "white")
g7<-ggplot(sub3, aes(x = vote_count)) + 
  geom_histogram(fill = "darkblue", color = "white")

grid.arrange(g1, g2, g3, g4, g5, g6, g7, ncol = 2)
```

```{r fig.cap="Predictor vs. Response", message=FALSE, warning=FALSE}
# create scatter plots between each quantitative predictor var and the response
#var to see their relationships
s.popularity <- ggplot(sub3, aes(x = popularity, y = revenue)) +
  geom_point(color = "darkblue") 
s.budget <- ggplot(sub3, aes(x = budget, y = revenue)) +
  geom_point(color = "darkblue") 
s.runtime <- ggplot(sub3, aes(x = runtime, y = revenue)) +
  geom_point(color = "darkblue") 
s.vote_average <- ggplot(sub3, aes(x = vote_average, y = revenue)) +
  geom_point(color = "darkblue") 
s.vote_count <- ggplot(sub3, aes(x = vote_count, y = revenue)) +
  geom_point(color = "darkblue")

## create boxplots between each categorical predictor and the response
box.genres <- ggplot(sub3, aes(x = genres, y = revenue)) +
           geom_boxplot(color = "darkblue", outlier.color = "red",
                        outlier.shape = 4, outlier.size = 2) 
box.original_language <- ggplot(sub3, aes(x = original_language, y = revenue)) +
              geom_boxplot(color = "darkblue", outlier.color = "red",
                           outlier.shape = 4, outlier.size = 2) 

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(s.popularity, s.budget, s.runtime, s.vote_average, s.vote_count,
             box.genres, box.original_language, ncol = 4, nrow = 2)
```

```{r fig.cap="Initial Pairwise Comparison", message=FALSE, warning=FALSE}
# correlation between variables 
ggpairs(sub3) + theme(axis.text.x = element_text(size= 2, angle = 90),
                      axis.text.y = element_text(size = 2),
                      strip.text.y = element_text(angle = 0))
```

## Forward Stepwise Regression

```{r, message=FALSE, warning=FALSE}
# perform stepwise regression using the original data set

# specify the null model with no predictor
original.null <- lm(revenue ~ 1, data = sub3)

# specify the full model using all of the potential predictors
original.full <- lm(revenue ~ ., data = sub3)

# use the stepwise algorithm to build a parsimonious model
original.step <- step(original.null,
                      scope = list(lower = original.null,
                                   upper = original.full),
                      direction = "both", test = "F")

summary(original.step)
```

According to the final output of the stepwise regression model analysis above,
the significant predictors are *vote_count*, *budget*, *popularity*, and
*genres*. Predictors *vote_average* and *runtime* are not statistically
significant and have been excluded from the final stepwise model.

## Residual Diagnostics

```{r fig.cap="Residual Diagnostics: Linearity", message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check linearity
ggplot(data = original.step, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Predicted Values", y = "Residuals")
# predictor: vote count
l.vc <- ggplot(data = original.step, aes(x = vote_count, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "vote count", y = "Residuals")
# predictor: budget
l.budget <- ggplot(data = original.step, aes(x = budget, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "budget (in thousand $)", y = "Residuals")
# predictor: popularity
l.popularity <- ggplot(data = original.step, aes(x = popularity, y = .resid)) +
  geom_point(alpha = 0.5, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "popularity", y = "Residuals")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(l.vc, l.budget, l.popularity, ncol = 3, nrow = 1)
```

Only *popularity* passed the linearity check as it showed no distinct pattern.

```{r fig.cap="Residual Diagnostics: Constant Variance", message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check constant variance
set.seed(123)
bptest(original.step)
```

Because the $p$-value < 2.2$e^{-16}$ is much less than the significance level
$\alpha$ = 0.05, we can reject the null hypothesis. Therefore, there is
sufficient evidence to conclude the residuals do not have constant variance. 

```{r fig.cap="Residual Diagnostics: Normality", message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check normality 
ggplot(data = original.step, aes(x = .resid)) + 
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand $)", y = "count")

ggplot(data = original.step, aes(x = .resid)) + 
  geom_boxplot(color = "darkblue", outlier.color = "red",
               outlier.shape = 4, outlier.size = 2) +
           labs(y = "revenue (in thousand $)")

qqnorm(resid(original.step))
qqline(resid(original.step))

set.seed(123)
shapiro.test(resid(original.step))
```

The residuals do not appear to be normally distributed due to the following
reasons: 

1. The histogram is slightly right-skewed instead of bell-shaped.
2. The mean is not centered at 0 in the boxplot.
3. The right tail of the Q-Q plot deviates significantly from the fitted Q-Q
line.
4. The Shapiro-Wilk test $p$-value < 2.2$e^{-16}$ is much less than the
significance level $\alpha$ = 0.05, suggesting that we can reject the null
hypothesis that the residuals are normally distributed.

```{r, message=FALSE, warning=FALSE}
# perform residual diagnostics on the residuals of the final stepwise model

# check independence
set.seed(123)
durbinWatsonTest(original.step)
```

Because the $p$-value = 0.618 is greater than the significance level $\alpha$ =
0.05, we cannot reject the null hypothesis. Therefore, there is insufficient
evidence to conclude that the residuals are not independent.

## Model Building and Diagnostics

```{r, message=FALSE, warning=FALSE}
rev <- sub3$revenue
vc <- sub3$vote_count
budget <- sub3$budget
pop <- sub3$popularity
va <- sub3$vote_average
rt <- sub3$runtime

# create dummy variables for each cat var
genre <- ifelse(sub3$genres == "Drama", 1, 0)
o_lang <- ifelse(sub3$original_language == "en", 1, 0)
```

```{r fig.cap="Initial Plots of Predictor vs. Response Variables", message=FALSE, warning=FALSE}
# check the relationship between each predictor var and rev
a <- ggplot(sub3, aes(x = budget, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "revenue (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "revenue (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "revenue (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "revenue (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "revenue (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "revenue (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = rev)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "revenue (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

### Model Building

```{r fig.cap="Interaction Between popularity and genres", message=FALSE, warning=FALSE}
# check interaction between popularity and genre
plot(pop, rev, type = "n")
points(pop[genre == 0], rev[genre == 0], col="darkblue")
points(pop[genre == 1], rev[genre == 1], col="darkred")
```

The two variables are overlapping, implying an interaction between the two. 

```{r fig.cap="Residual Diagnostics: y1", message=FALSE, warning=FALSE}
lm1 <- lm(rev ~ 0 + pop * genre)
y1 <- lm1$residuals

ggplot(sub3, aes(x = y1))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand $)", y = "count")
qqnorm(y1)
qqline(y1)
shapiro.test(y1)
```

```{r fig.cap="Plots of Predictors vs. y1", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y1
a <- ggplot(sub3, aes(x = budget, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "revenue (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "revenue (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "revenue (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "revenue (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "revenue (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "revenue (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "revenue (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

Model 1 was fitted with an interaction between *popularity* and *generes*, with
an intercept set to 0. 

As shown by the results, Model 1 does not pass the Shapiro-Wilk normality test
and appears right-skewed.

According to the scatter plots for each individual predictor variable against
the Model 1 residuals, most predictors exhibited patterns except for *budget*,
*popularity*, and *vote_count*. These three variables will be further observed
before we decide whether to exclude them in the model.

```{r fig.cap="Residual Diagnostics: y2", message=FALSE, warning=FALSE}
lm2 <- lm(y1 ~ 0 + budget)
y2 <- lm2$residuals

ggplot(sub3, aes(x = y2))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "revenue (in thousand $)", y = "count")
qqnorm(y2)
qqline(y2)
shapiro.test(y2)
```

```{r fig.cap="Plots of Predictors vs. y2", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y1
a <- ggplot(sub3, aes(x = budget, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "revenue (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "revenue (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "revenue (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "revenue (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "revenue (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "revenue (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "revenue (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

Model 2 was fitted with *budget*, with an intercept set to 0. 

Like Model 1, Model 2 does not pass the Shapiro-Wilk normality test and appears 
right-skewed.

The scatter plots still show that *budget*, *popularity*, and *vote_count* to
have no effect on the response variable Moreover, *genres* seems to have become 
constant as well. Since *budget* and *genres* are the two variables that we 
wanted to focus on as stated in our hypothesis, we have decided to perform a 
logarithmic transformation on *revenue* to see if this will make a difference. 

```{r fig.cap="Plots of Predictor vs. lnrev", message=FALSE, warning=FALSE}
# perform log transformation on revenue and edit the original data set to
# exclude revenue and include lnrev
lnrev <- log(sub3$revenue)
sub3$lnrev <- lnrev
sub3 <- sub3[, -5]

# convert cat vars genres and original language to be binary data
sub3$genres <- genre
sub3$original_language <- o_lang

# check the relationship between each predictor variable and lnrev
a <- ggplot(sub3, aes(x = budget, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "lnrev (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "lnrev (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "lnrev (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "lnrev (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "lnrev (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "lnrev (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = lnrev)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "lnrev (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

```{r fig.cap="Interaction Between popularity and genres", message=FALSE, warning=FALSE}
# check interaction between pop and genre
plot(pop, lnrev, type = "n")
points(pop[genre == 0], lnrev[genre == 0], col="darkblue")
points(pop[genre == 1], lnrev[genre == 1], col="darkred")
```

Similar to the results from before, the two variables overlap, suggesting a
strong interaction between them.

```{r fig.cap="Residual Diagnostics: y1", message=FALSE, warning=FALSE}
lm1 <- lm(lnrev ~ 0 + pop * genre)
y1 <- lm1$residuals

ggplot(sub3, aes(x = y1))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")
qqnorm(y1)
qqline(y1)
shapiro.test(y1)
```

```{r fig.cap="Plots of Predictors vs. y1", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y1
a <- ggplot(sub3, aes(x = budget, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand dollars)", y = "lnrev (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "lnrev (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "lnrev (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "lnrev (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "lnrev (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "lnrev (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y1)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "lnrev (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

The new Model 1 was fitted with an interaction between *popularity* and
*genres*, with an intercept set to 0. 

It does not pass the Shapiro-Wilk normality test and now appears slightly
left-skewed.

All variables now appear to impact *lnrev* except *vote_average*. This means
that our transformation has made a difference. We will continue to monitor
*vote_average* before deciding whether or not to exclude it from the model.

```{r fig.cap="Residual Diagnostics: y2", message=FALSE, warning=FALSE}
lm2 <- lm(y1 ~ 0 + budget)
y2 <- lm2$residuals

ggplot(sub3, aes(x = y2))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")
qqnorm(y2)
qqline(y2)
shapiro.test(y2)
```

```{r fig.cap="Plots of Predictors vs. y2", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y2
a <- ggplot(sub3, aes(x = budget, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "lnrev (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "lnrev (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "lnrev (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "lnrev (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "lnrev (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "lnrev (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y2)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "lnrev (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

The new Model 2 was fitted with a single variable *budget* and a 0 intercept.

It still does not pass the Shapiro-Wilk normality test and is slightly
left-skewed.

*vote_average* again exhibits no pattern, implying it does affect *lnrev*, and *runtime* now looks more constant than before. All the other variables seem
to be impacting y.

```{r fig.cap="Residual Diagnostics: y3", message=FALSE, warning=FALSE}
lm3 <- lm(y2 ~ 0 + vc)
y3 <- lm3$residuals

ggplot(sub3, aes(x = y3))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")
qqnorm(y3)
qqline(y3)
shapiro.test(y3)
```

```{r fig.cap="Plots of Predictors vs. y3", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y3
a <- ggplot(sub3, aes(x = budget, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "budget (in thousand $)", y = "lnrev (in thousand $)")
b <- ggplot(sub3, aes(x = runtime, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "runtime (in minutes)", y = "lnrev (in thousand $)")
c <- ggplot(sub3, aes(x = popularity, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "lnrev (in thousand $)")
d <- ggplot(sub3, aes(x = vote_count, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "lnrev (in thousand $)")
e <- ggplot(sub3, aes(x = vote_average, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "va", y = "lnrev (in thousand $)")
f <- ggplot(sub3, aes(x = genres, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "lnrev (in thousand $)")
g <- ggplot(sub3, aes(x = original_language, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "lnrev (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, f, g, ncol = 3, nrow = 3)
```

Model 3 was fitted with *vote_count* and an intercep of 0. 

Like the previous two models, this model is left-skewed and does not pass the Shapiro-Wilk test.

We will be taking out *vote_average* and *runtime*, with the latter collapsing
more, as these two look constant compared to all other variables.

Before continuing further analysis, we have decided to transform *popularity*
with a square root transformation for easier computation and model fitting and
hoping this will help us pass the normality assumption check.

```{r fig.cap="Residual Diagnostics: y4", message=FALSE, warning=FALSE}
# perform square root transformation on popularity and edit the data set to
# exclude popularity and include popsqrt
popsqrt <- sqrt(pop)
sub3$popsqrt <- popsqrt
sub3 <- sub3[, -3]

# fit the model using the interaction between popsqrt and genres
lm4 <- lm(y3 ~ 0 + popsqrt * genre)
y4 <- lm4$residuals

ggplot(sub3, aes(x = y4))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")
qqnorm(y4)
qqline(y4)
shapiro.test(y4)
```

```{r fig.cap="Plots of Predictors vs. y4", message=FALSE, warning=FALSE}
# check the relationship between each predictor variable and y4
a <- ggplot(sub3, aes(x = budget, y = y4)) +
  geom_point(color = "darkblue")+
  labs(x = "budget (in thousand $)", y = "lnrev (in thousand $)")
b <- ggplot(sub3, aes(x = popsqrt, y = y4)) +
  geom_point(color = "darkblue") +
  labs(x = "popularity", y = "lnrev (in thousand $)")
c <- ggplot(sub3, aes(x = vote_count, y = y4)) +
  geom_point(color = "darkblue") +
  labs(x = "vc", y = "lnrev (in thousand $)")
d <- ggplot(sub3, aes(x = genres, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "genres", y = "lnrev (in thousand $)")
e <- ggplot(sub3, aes(x = original_language, y = y3)) +
  geom_point(color = "darkblue") +
  labs(x = "original lang", y = "lnrev (in thousand $)")

# divide the frame in grid using grid.arrange() and put above plots in it
grid.arrange(a, b, c, d, e, ncol = 3, nrow = 2)
```

Model 3 residuals were used as my response for Model 4, which incorporated the
interaction between *popsqrt* and *genres* with a 0 intercept.

While the residuals of the new model still failed the Shapiro-Wilk test and
appear to be left-skewed, all predictors were shown to be affecting *lnrev*.

```{r fig.cap="Residual Diagnostics: lm5", message=FALSE, warning=FALSE}
# fit first full model
lm5 <- lm(lnrev ~ 0 + budget + popsqrt * genre + o_lang + vc)
summary(lm5)

# check the residual assumptions
ggplot(sub3, aes(x = lm5$residuals))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")
qqnorm(lm5$residuals)
qqline(lm5$residuals)
ggplot(sub3, aes(x = lm5$fitted.values, y = lm5$residuals)) +
  geom_point(color = "darkblue") +
  labs(x = "Fitted Values", y = "Residuals")

set.seed(123)
shapiro.test(lm5$residuals)
durbinWatsonTest(lm5)
bptest(lm5)
```

Although this model produced a high adjusted $R^2$ value of 0.9578, the
residuals of this model did not pass the normality check, did not exhibit
significant autocorrelation, and lacked homoscedasticity.

All predictors are shown to be statistically significant.

```{r fig.cap="Pairwise Comparison for Model 4", message=FALSE, warning=FALSE}
# edit the data set to exclude runtime and vote average
sub3 <- sub3[, -c(4, 5)]

# create pairwise scatter plots and coefficient of correlation
ggpairs(sub3) + theme(axis.text.x = element_text(size= 2.5, angle = 90),
                      axis.text.y = element_text(size = 2.5),
                      strip.text.y = element_text(angle = 0))
```

Similar to the results of our initial pairwise comparison, majority of the
predictor variables do not exhibit multicollinearity. An intermediate
correlation between *budget* and *lnrev* is expected, as this is one of the
variables we wanted to take a closer look at and one of our hypotheses.

```{r, message=FALSE, warning=FALSE}
# perform forward stepwise regression and use this model as Model 6

# specify a null model with no predictors
null.model <- lm(lnrev ~ 0, data = sub3)

# use a stepwise algorithm to build a parsimonious model
# null to full
lm6 <- step(null.model,
            scope = list(lower = null.model, upper = lm5),
            direction = "both", test = "F")
summary(lm6)

# check the residual assumptions
ggplot(sub3, aes(x = lm6$residuals))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")
qqnorm(lm6$residuals)
qqline(lm6$residuals)
ggplot(sub3, aes(x = lm6$fitted.values, y = lm6$residuals)) +
  geom_point(color = "darkblue") +
  labs(x = "Fitted Values", y = "Residuals")

set.seed(123)
shapiro.test(lm6$residuals)
durbinWatsonTest(lm6)
bptest(lm6)
```

Model 6 yielded the exact same results as Model 5. Therefore, there's no need
to do further model comparison, and we choose Model 5 as our final model.

### Final Model Diagnostics

```{r, message=FALSE, warning=FALSE}
final.model <- lm(lnrev ~ 0 + budget + popsqrt * genre + o_lang + vc)

# non-significant F-tests with overall significant F-test
summary(final.model)

# variance inflation factor (VIF)
vif(final.model)

# check the residual assumptions
ggplot(sub3, aes(x = final.model$residuals))+
  geom_histogram(fill = "darkblue", color = "white") +
  labs(x = "lnrev (in thousand $)", y = "count")

qqnorm(final.model$residuals)
qqline(final.model$residuals)
ggplot(sub3, aes(x = final.model$fitted.values, y = final.model$residuals)) +
  geom_point(color = "darkblue") +
  labs(x = "Fitted Values", y = "Residuals")

set.seed(123)
shapiro.test(final.model$residuals)
durbinWatsonTest(final.model)
bptest(final.model)
```

The final model has a robust adjusted $R^2$ value of 0.9578. It also
demonstrates statistical significance by rejecting my null hypothesis with a
$p$-value much below the predetermined significance level $\alpha$ = 0.05.

However, our final model did not pass the normality or the constant variance
checks. The model also has VIF scores below 10 between its predictors. This
also corresponds to the results of the pairwise comparisons.

In conclusion, regardless of its shortcomings, we accept Model 5 as our final
model.

# Differential Privacy

```{r}
library(diffpriv)

set.seed(111)  # for reproducibility

# define target function for linear regression coefficients with intercept
target_function <- function(X) {
  model_sim <- lm(lnrev ~ budget + popsqrt * genre + o_lang + vc, data = X)
  return(coef(model_sim))  # returns coefficients including the intercept
}

# define the Laplace mechanism
# the sample size is 2624
# dims = 7 because there's 1 intercept and 6 variables
mechanism <- DPMechLaplace(target = target_function, sensitivity = 1 / 2624,
                           dims = 7)

# set privacy parameters
privacy_params_sim <- DPParamsEps(epsilon = 1)

# generate private response for one run
private_response <- releaseResponse(mechanism,
                                    privacyParams = privacy_params_sim,
                                    X = sub3)

# display non-private and private coefficients for comparison
cat("Non-private coefficients:\n", coef(lm(lnrev ~ budget + popsqrt * genre + o_lang + vc, data = sub3)), "\n")
cat("Private coefficients:\n", private_response$response, "\n")
```

## Simulations

```{r}
set.seed(111)  

n_simulations <- 1000
private_coefficients <- replicate(
  n_simulations,
  releaseResponse(mechanism, privacyParams = privacy_params_sim, X = sub3)$response
)

# get non-private coefficients
non_private_coeffs <- coef(lm(lnrev ~ budget + popsqrt * genre + o_lang + vc, data = sub3))

# create a data frame for private coefficients
private_df <- as.data.frame(t(private_coefficients))
colnames(private_df) <- names(non_private_coeffs)
private_df$Simulation <- seq_len(n_simulations)

# reshape data for plotting
private_long <- private_df %>%
  pivot_longer(cols = -Simulation, names_to = "Coefficient", values_to = "Value")

# prepare non-private coefficients for plotting
non_private_df <- data.frame(
  Coefficient = names(non_private_coeffs),
  Value = as.numeric(non_private_coeffs)
)

# plot private vs. non-private coefficients
ggplot() +
  geom_density(data = private_long,
               aes(x = Value, fill = "Private"),
               alpha = 0.5) +
  geom_vline(data = non_private_df,
             aes(xintercept = Value,
                 linetype = "Non-Private"),
             color = "black", size = 0.5) +
  facet_wrap(~ Coefficient, scales = "free") +
  labs(title = "Distributions of Private vs. Non-Private Coefficients",
       x = "Coefficient Value", y = "Density",
       fill = "Type", linetype = "Type") +
  scale_fill_manual(values = c("Private" = "red")) +
  scale_linetype_manual(values = c("Non-Private" = "dashed")) +
  theme_minimal()

# validate means of private and non-private coefficients
cat("Mean of private budget coefficient:\n", mean(private_df$genre), "\n")
cat("Non-private budget coefficient:\n", non_private_coeffs["genre"], "\n")
```

### Give the filter dataset in CSV
```{r,eval=FALSE}
library(readr)
write_csv(sub3, "dataset_filtered.csv")


```

