---
title: "STAT 206 Final Project Report"
author: "Axel Galicia Lona, Linlin Liu, amd Nancy Lopez"
date: "2024-12-13"
echo: true
format:
  html:
    toc: true
    toc-location: left
    embed-resources: true
    code-line-numbers: true
  pdf:
    code-line-numbers: true
---

\newpage
\tableofcontents
\newpage
\listoffigures
\newpage
\listoftables
\newpage

# Introduction

## Background and Motivation

Movies are a visual art form that simulates and communicates thoughts, actions,
ideas, and realities by combining camera recordings with sound. With rapid
population expansion and technical improvement, the movie industry grows
increasingly sophisticated. The industry's maturity has also boosted the rate
at which movies are made and produced, and every year, a new batch of films is  released in theaters. Therefore, studios, producers, and investors need
reliable predictions to make informed decisions about budgeting, marketing,
and resource allocation.

As viewers, we are also interested in the factors that contribute to a film's
revenue, because these generally define its success. Furthermore, the highly competitive nature of the film industry, as well as the huge economic impact of
movie income, motivated us to pursue this project. With abundant data available
on various aspects of movies, including budget, cast, genre, release dates, and
social media buzz, applying statistical models becomes a valuable tool for
analysis. Thus, we chose to build a multilinear regression model for our
project.

Differential privacy is crucial for datasets containing sensitive aspects of
movies, such as budget, revenue, cast, and others, as it ensures that
individual data points cannot be traced back to their sources. For instance,
protecting details like a movie's budget prevents competitors from exploiting
financial strategies, while preserving anonymity in user-related data
safeguards privacy rights. By adding controlled random noise to the data,
differential privacy balances utility with confidentiality, enabling meaningful analysis without exposing proprietary or personal information.

# Introduction To Differential Privacy

Differential Privacy (DP) is a statistical framework designed to protect individuals' sensitive information in a dataset. It protects privacy by adding random noise to the outputs of data analyses before they are shared with any third-party such as scientists, companies, or other analysts. This ensures that no single individual's data can be identified or inferred, even if someone has additional knowledge about the dataset. The goal of DP is to balance privacy protection with the need for accurate and meaningful data analysis, allowing organizations to extract valuable insights without compromising individual privacy.

The formal definition of DP states that for any 2 datasets, D and D' differing by one individual data point, the probability of mechanism M producing a certain result should be very close for both datasets. This can be mathematically expressed as: $Pr(M(D) \in R) \leq exp(\epsilon) * Pr(M(D') \in R) $ where $\epsilon$ is the privacy parameter. A small privacy parameter means strong privacy since the output reveals less information about individual data. By having two similar datasets, one missing a data point, it becomes extremely difficult to guess whether a specific persons data was used; therefore protecting individuals privacy. 

A good noise-adding mechanism should privatize data while maintaining its usefulness, enabling meaningful analysis without risking individualsâ€™ sensitive information. This method is particularly important in today's world, where vast amounts of data are constantly being collected. From our phones and social media platforms to streaming services and other technologies, our data is tracked to provide better algorithms and more personalized recommendations. DP plays a crucial role in protecting our privacy in fields like healthcare, technology, and beyond.
 
## DP Examples

-   can talk about usage in modern world

# Noise Implementation Methods

-   the types of noise implantation

# DiffPriv package

-   what the diffpriv package is and how it works

# Implementation of DiffPriv

-   now for our example of using diffpriv with linear model.
